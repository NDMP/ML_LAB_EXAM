import numpy as np

# Dataset (AND gate)
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[0],[0],[1]])

# Sigmoid & derivative
def sigmoid(x): return 1 / (1 + np.exp(-x))
def dsigmoid(x): return x * (1 - x)

# Initialize weights
w1 = np.random.uniform(size=(2,2))
w2 = np.random.uniform(size=(2,1))

lr = 0.1   # learning rate

# Training
for _ in range(1500):
    # Forward pass
    h = sigmoid(np.dot(X, w1))
    o = sigmoid(np.dot(h, w2))

    # Backpropagation
    error = y - o
    d_o = error * dsigmoid(o)
    d_h = d_o.dot(w2.T) * dsigmoid(h)

    # Weight update
    w2 += h.T.dot(d_o) * lr
    w1 += X.T.dot(d_h) * lr

# Final Output
print("Final Weights:\n", w1, "\n", w2)
print("\nPredicted Output:\n", o)
